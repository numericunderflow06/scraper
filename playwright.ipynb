{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c177aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import re\n",
    "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError, Error as PlaywrightError\n",
    "\n",
    "async def scrape_xueqiu_playwright_async(url):\n",
    "    \"\"\"\n",
    "    Scrapes the main post and comments from a Xueqiu article URL using Playwright's Async API.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the Xueqiu post.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing 'main_post' and 'comments' list.\n",
    "    \"\"\"\n",
    "    scraped_data = {\"main_post\": None, \"comments\": []}\n",
    "    browser = None\n",
    "\n",
    "    print(\"--- Starting Playwright Async Scraper ---\")\n",
    "    try:\n",
    "        async with async_playwright() as p:\n",
    "            print(\"Launching Chromium browser (async)...\")\n",
    "            browser = await p.chromium.launch(headless=False, args=[\"--start-maximized\"])\n",
    "            context = await browser.new_context(\n",
    "                no_viewport=True,\n",
    "                user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36\",\n",
    "                locale=\"zh-CN\"\n",
    "            )\n",
    "            page = await context.new_page()\n",
    "\n",
    "            print(f\"Navigating to: {url} (async)\")\n",
    "            await page.goto(url, timeout=60000, wait_until='domcontentloaded')\n",
    "            print(\"Page loaded (DOM content). Waiting for potential dynamic elements...\")\n",
    "            await page.wait_for_timeout(2000)\n",
    "\n",
    "            # --- Handle Pop-ups (Async) ---\n",
    "            popup_timeout = 10000\n",
    "\n",
    "            # 1. First Pop-up (\"跳过\")\n",
    "            print(\"Looking for the first pop-up ('跳过')...\")\n",
    "            skip_locator_css = 'span:text-is(\"跳过\"), button:has-text(\"跳过\")'\n",
    "            try:\n",
    "                skip_button = page.locator(skip_locator_css).first\n",
    "                await skip_button.wait_for(state='visible', timeout=popup_timeout)\n",
    "                print(\"First pop-up '跳过' button found. Clicking...\")\n",
    "                await skip_button.click(timeout=5000)\n",
    "                print(\"Clicked '跳过'.\")\n",
    "                await page.wait_for_timeout(1000)\n",
    "            except PlaywrightTimeoutError: # Use the aliased TimeoutError\n",
    "                print(\"First pop-up ('跳过') did not appear or timed out.\")\n",
    "            except PlaywrightError as e:\n",
    "                print(f\"Error interacting with first pop-up: {e}\")\n",
    "\n",
    "            # 2. Second Pop-up (\"X\")\n",
    "            print(\"Looking for the second pop-up ('X')...\")\n",
    "            close_selectors_css = [\n",
    "                \"div.modal-wrapper i.icon-close\", \"div.xq-dialog-wrapper i.close\",\n",
    "                \"i.cube-dialog-close\", \"div.Modal_modal i.Modal_closeIcon\",\n",
    "                \"div[aria-label='Close']\", \"button[aria-label='Close']\",\n",
    "            ]\n",
    "            close_button_found = False\n",
    "            for selector in close_selectors_css:\n",
    "                try:\n",
    "                    print(f\"Trying close selector: {selector}\")\n",
    "                    close_button = page.locator(selector).first\n",
    "                    await close_button.wait_for(state='visible', timeout=popup_timeout / len(close_selectors_css))\n",
    "                    print(f\"Second pop-up 'X' button found with selector: {selector}. Clicking...\")\n",
    "                    await close_button.click(timeout=5000)\n",
    "                    print(\"Clicked 'X' on the second pop-up.\")\n",
    "                    close_button_found = True\n",
    "                    await page.wait_for_timeout(1000)\n",
    "                    break\n",
    "                except PlaywrightTimeoutError: continue\n",
    "                except PlaywrightError as e: print(f\"Error interacting with second pop-up using selector '{selector}': {e}\"); continue\n",
    "            if not close_button_found: print(\"Second pop-up (close 'X') not found with attempted selectors.\")\n",
    "\n",
    "            # --- Scrape Main Post Content (Async) ---\n",
    "            print(\"Scraping main post content...\")\n",
    "            post_locator_css = \"div.article__content, div.article__bd__detail\"\n",
    "            try:\n",
    "                post_element = page.locator(post_locator_css).first\n",
    "                await post_element.wait_for(state=\"visible\", timeout=20000)\n",
    "                scraped_data[\"main_post\"] = await post_element.text_content()\n",
    "                print(\"Main post content scraped successfully.\")\n",
    "            except PlaywrightTimeoutError: print(\"Main post content not found or not visible.\"); await page.screenshot(path=\"playwright_debug_no_main_post.png\")\n",
    "            except PlaywrightError as e: print(f\"Error scraping main post: {e}\"); await page.screenshot(path=\"playwright_debug_error_main_post.png\")\n",
    "\n",
    "            # --- Click on Comments Tab (Async) ---\n",
    "            comments_tab_clicked = False\n",
    "            print(\"Looking for the '评论' (Comments) tab...\")\n",
    "            tab_locator_css = \"div.tabs__item:has(span:text-is('评论')), div.action-bar__item:has-text('评论')\"\n",
    "            try:\n",
    "                comments_tab = page.locator(tab_locator_css).first\n",
    "                await comments_tab.wait_for(state=\"visible\", timeout=20000)\n",
    "                print(\"Comments tab found. Clicking...\")\n",
    "                await comments_tab.click(timeout=10000)\n",
    "                print(\"Clicked '评论' tab.\")\n",
    "                comments_tab_clicked = True\n",
    "                await page.wait_for_timeout(2500)\n",
    "            except PlaywrightTimeoutError: print(\"Comments tab ('评论') not found or not visible/clickable.\"); await page.screenshot(path=\"playwright_debug_no_comment_tab.png\")\n",
    "            except PlaywrightError as e: print(f\"Error clicking comments tab: {e}\"); await page.screenshot(path=\"playwright_debug_error_comment_tab.png\")\n",
    "\n",
    "            # --- Scrape Comments (Async) ---\n",
    "            if comments_tab_clicked:\n",
    "                print(\"Attempting to scrape comments...\")\n",
    "                print(\"Scrolling down page...\")\n",
    "                await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight*0.8)\")\n",
    "                await page.wait_for_timeout(1000)\n",
    "                await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "                await page.wait_for_timeout(2000)\n",
    "\n",
    "                comment_locator_css = \"div.comment__item__main > p\"\n",
    "                print(f\"Waiting for the first comment element ('{comment_locator_css}') to be visible...\")\n",
    "                try:\n",
    "                    await page.locator(comment_locator_css).first.wait_for(state=\"visible\", timeout=25000)\n",
    "                    print(\"First comment element visible.\")\n",
    "                    print(\"Extracting all comment texts...\")\n",
    "                    comment_elements = page.locator(comment_locator_css)\n",
    "                    all_texts = await comment_elements.all_text_contents()\n",
    "\n",
    "                    if all_texts:\n",
    "                        count = 0\n",
    "                        for text in all_texts:\n",
    "                            cleaned_text = text.strip()\n",
    "                            if cleaned_text and \"回复@\" not in cleaned_text[:5] and \"查看回复\" not in cleaned_text and \"查看对话\" not in cleaned_text:\n",
    "                                scraped_data[\"comments\"].append(cleaned_text)\n",
    "                                count += 1\n",
    "                        print(f\"Successfully scraped {count} non-empty comments.\")\n",
    "                    else: print(\"Located comment elements, but failed to extract text.\"); await page.screenshot(path=\"playwright_debug_comments_found_but_empty.png\")\n",
    "                except PlaywrightTimeoutError:\n",
    "                    print(f\"Timed out waiting for the first comment element ('{comment_locator_css}') to become visible.\")\n",
    "                    await page.screenshot(path=\"playwright_debug_timeout_waiting_for_comments.png\")\n",
    "                except PlaywrightError as e: print(f\"Error scraping comments: {e}\"); await page.screenshot(path=\"playwright_debug_error_scraping_comments.png\")\n",
    "            else: print(\"Skipping comment scraping because '评论' tab was not successfully clicked.\")\n",
    "\n",
    "            print(\"\\n--- Taking final screenshot ---\")\n",
    "            await page.screenshot(path=\"playwright_final_state.png\")\n",
    "            print(\"Saved final screenshot: playwright_final_state.png\")\n",
    "\n",
    "            print(\"Closing browser context and browser (async)...\")\n",
    "            await context.close()\n",
    "            await browser.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- An critical error occurred during the Playwright Async process ---\")\n",
    "        print(f\"Error Type: {type(e).__name__}\")\n",
    "        print(f\"Error Details: {e}\")\n",
    "        if browser and not browser.is_closed(): # Check if browser exists and is not already closed\n",
    "            try:\n",
    "                print(\"Attempting to close browser after error (async)...\")\n",
    "                await browser.close()\n",
    "                print(\"Browser closed after error.\")\n",
    "            except Exception as close_err:\n",
    "                print(f\"Error closing browser after main error: {close_err}\")\n",
    "\n",
    "    print(\"--- Playwright Async Scraper Finished ---\")\n",
    "    return scraped_data\n",
    "\n",
    "# --- How to run in a Jupyter Notebook ---\n",
    "async def main():\n",
    "    target_url = \"https://xueqiu.com/5669998349/334081638\"\n",
    "    data = await scrape_xueqiu_playwright_async(target_url)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"      Scraped Data Summary (Playwright Async)\")\n",
    "    print(\"=\"*30)\n",
    "    print(\"\\n--- Main Post ---\")\n",
    "    if data[\"main_post\"]: print(data[\"main_post\"][:500] + ('...' if len(data[\"main_post\"]) > 500 else ''))\n",
    "    else: print(\">>> Main post content not found or scraping failed. <<<\")\n",
    "    print(\"\\n--- Comments ---\")\n",
    "    if data[\"comments\"]:\n",
    "        print(f\"Found {len(data['comments'])} comments:\")\n",
    "        for i, comment in enumerate(data[\"comments\"]): print(f\"{i+1}. {comment[:150]}\" + ('...' if len(comment) > 150 else ''))\n",
    "    else: print(\">>> No comments found or scraping failed. <<<\")\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"Check console logs and playwright_debug_*.png files for details.\")\n",
    "\n",
    "# To run this in a Jupyter Notebook cell, you execute it like this:\n",
    "# await main()\n",
    "#\n",
    "# Or, if you're in a regular Python script or an environment that\n",
    "# doesn't automatically handle top-level await (like older Python versions):\n",
    "# if __name__ == \"__main__\":\n",
    "# asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78de58a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Playwright Async Scraper ---\n",
      "\n",
      "--- An critical error occurred during the Playwright Async process ---\n",
      "Error Type: NotImplementedError\n",
      "Error Details: \n",
      "--- Playwright Async Scraper Finished ---\n",
      "\n",
      "==============================\n",
      "      Scraped Data Summary (Playwright Async)\n",
      "==============================\n",
      "\n",
      "--- Main Post ---\n",
      ">>> Main post content not found or scraping failed. <<<\n",
      "\n",
      "--- Comments ---\n",
      ">>> No comments found or scraping failed. <<<\n",
      "\n",
      "==============================\n",
      "Check console logs and playwright_debug_*.png files for details.\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af91489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import re\n",
    "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError, Error as PlaywrightError\n",
    "import nest_asyncio # <--- Import nest_asyncio\n",
    "\n",
    "# Apply nest_asyncio. This should be done once, at the top of your notebook or script.\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def scrape_xueqiu_playwright_async(url):\n",
    "    \"\"\"\n",
    "    Scrapes the main post and comments from a Xueqiu article URL using Playwright's Async API.\n",
    "    (Content of this function remains the same as the previous async version)\n",
    "    \"\"\"\n",
    "    scraped_data = {\"main_post\": None, \"comments\": []}\n",
    "    browser = None\n",
    "\n",
    "    print(\"--- Starting Playwright Async Scraper (with nest_asyncio) ---\")\n",
    "    try:\n",
    "        async with async_playwright() as p:\n",
    "            print(\"Launching Chromium browser (async)...\")\n",
    "            # Try without --start-maximized initially to see if it's related\n",
    "            browser = await p.chromium.launch(headless=False) # Removed args=[\"--start-maximized\"] for now\n",
    "            context = await browser.new_context(\n",
    "                # Keep viewport reasonable if not maximizing\n",
    "                # viewport={'width': 1280, 'height': 720}, # Example viewport\n",
    "                no_viewport=True, # Or stick to no_viewport if window maximization works\n",
    "                user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36\",\n",
    "                locale=\"zh-CN\"\n",
    "            )\n",
    "            page = await context.new_page()\n",
    "            # If not using no_viewport, you might need to maximize after page creation\n",
    "            # await page.set_viewport_size({\"width\": 1920, \"height\": 1080}) # If needed\n",
    "\n",
    "            print(f\"Navigating to: {url} (async)\")\n",
    "            await page.goto(url, timeout=60000, wait_until='domcontentloaded')\n",
    "            print(\"Page loaded (DOM content). Waiting for potential dynamic elements...\")\n",
    "            await page.wait_for_timeout(3000) # Increased initial wait\n",
    "\n",
    "            # --- Handle Pop-ups (Async) ---\n",
    "            popup_timeout = 10000\n",
    "\n",
    "            # 1. First Pop-up (\"跳过\")\n",
    "            print(\"Looking for the first pop-up ('跳过')...\")\n",
    "            skip_locator_css = 'span:text-is(\"跳过\"), button:has-text(\"跳过\")'\n",
    "            try:\n",
    "                skip_button = page.locator(skip_locator_css).first\n",
    "                await skip_button.wait_for(state='visible', timeout=popup_timeout)\n",
    "                print(\"First pop-up '跳过' button found. Clicking...\")\n",
    "                await skip_button.click(timeout=5000, force=True) # Try with force=True\n",
    "                print(\"Clicked '跳过'.\")\n",
    "                await page.wait_for_timeout(1500) # Increased pause\n",
    "            except PlaywrightTimeoutError:\n",
    "                print(\"First pop-up ('跳过') did not appear or timed out.\")\n",
    "            except PlaywrightError as e:\n",
    "                print(f\"Error interacting with first pop-up: {e}\")\n",
    "\n",
    "            # 2. Second Pop-up (\"X\")\n",
    "            print(\"Looking for the second pop-up ('X')...\")\n",
    "            close_selectors_css = [\n",
    "                \"div.modal-wrapper i.icon-close\", \"div.xq-dialog-wrapper i.close\",\n",
    "                \"i.cube-dialog-close\", \"div.Modal_modal i.Modal_closeIcon\",\n",
    "                \"div[aria-label='Close']\", \"button[aria-label='Close']\",\n",
    "            ]\n",
    "            close_button_found = False\n",
    "            for selector in close_selectors_css:\n",
    "                try:\n",
    "                    print(f\"Trying close selector: {selector}\")\n",
    "                    close_button = page.locator(selector).first\n",
    "                    await close_button.wait_for(state='visible', timeout=popup_timeout / len(close_selectors_css))\n",
    "                    print(f\"Second pop-up 'X' button found with selector: {selector}. Clicking...\")\n",
    "                    await close_button.click(timeout=5000, force=True) # Try with force=True\n",
    "                    print(\"Clicked 'X' on the second pop-up.\")\n",
    "                    close_button_found = True\n",
    "                    await page.wait_for_timeout(1500) # Increased pause\n",
    "                    break\n",
    "                except PlaywrightTimeoutError: continue\n",
    "                except PlaywrightError as e: print(f\"Error interacting with second pop-up using selector '{selector}': {e}\"); continue\n",
    "            if not close_button_found: print(\"Second pop-up (close 'X') not found with attempted selectors.\")\n",
    "\n",
    "            # --- Scrape Main Post Content (Async) ---\n",
    "            print(\"Scraping main post content...\")\n",
    "            post_locator_css = \"div.article__content, div.article__bd__detail\"\n",
    "            try:\n",
    "                post_element = page.locator(post_locator_css).first\n",
    "                await post_element.wait_for(state=\"visible\", timeout=20000)\n",
    "                scraped_data[\"main_post\"] = await post_element.text_content()\n",
    "                print(\"Main post content scraped successfully.\")\n",
    "            except PlaywrightTimeoutError: print(\"Main post content not found or not visible.\"); await page.screenshot(path=\"playwright_debug_no_main_post.png\")\n",
    "            except PlaywrightError as e: print(f\"Error scraping main post: {e}\"); await page.screenshot(path=\"playwright_debug_error_main_post.png\")\n",
    "\n",
    "            # --- Click on Comments Tab (Async) ---\n",
    "            comments_tab_clicked = False\n",
    "            print(\"Looking for the '评论' (Comments) tab...\")\n",
    "            tab_locator_css = \"div.tabs__item:has(span:text-is('评论')), div.action-bar__item:has-text('评论')\"\n",
    "            try:\n",
    "                comments_tab = page.locator(tab_locator_css).first\n",
    "                await comments_tab.wait_for(state=\"visible\", timeout=25000) # Increased wait\n",
    "                print(\"Comments tab found. Clicking...\")\n",
    "                await comments_tab.click(timeout=10000, force=True) # Try with force=True\n",
    "                print(\"Clicked '评论' tab.\")\n",
    "                comments_tab_clicked = True\n",
    "                await page.wait_for_timeout(3000) # Increased wait\n",
    "            except PlaywrightTimeoutError: print(\"Comments tab ('评论') not found or not visible/clickable.\"); await page.screenshot(path=\"playwright_debug_no_comment_tab.png\")\n",
    "            except PlaywrightError as e: print(f\"Error clicking comments tab: {e}\"); await page.screenshot(path=\"playwright_debug_error_comment_tab.png\")\n",
    "\n",
    "            # --- Scrape Comments (Async) ---\n",
    "            if comments_tab_clicked:\n",
    "                print(\"Attempting to scrape comments...\")\n",
    "                print(\"Scrolling down page...\")\n",
    "                await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight*0.8)\")\n",
    "                await page.wait_for_timeout(1500) # Increased\n",
    "                await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "                await page.wait_for_timeout(2500) # Increased wait after scroll\n",
    "\n",
    "                comment_locator_css = \"div.comment__item__main > p\"\n",
    "                print(f\"Waiting for the first comment element ('{comment_locator_css}') to be visible...\")\n",
    "                try:\n",
    "                    await page.locator(comment_locator_css).first.wait_for(state=\"visible\", timeout=30000) # Increased wait\n",
    "                    print(\"First comment element visible.\")\n",
    "                    print(\"Extracting all comment texts...\")\n",
    "                    comment_elements = page.locator(comment_locator_css)\n",
    "                    all_texts = await comment_elements.all_text_contents()\n",
    "\n",
    "                    if all_texts:\n",
    "                        count = 0\n",
    "                        for text in all_texts:\n",
    "                            cleaned_text = text.strip()\n",
    "                            if cleaned_text and \"回复@\" not in cleaned_text[:5] and \"查看回复\" not in cleaned_text and \"查看对话\" not in cleaned_text:\n",
    "                                scraped_data[\"comments\"].append(cleaned_text)\n",
    "                                count += 1\n",
    "                        print(f\"Successfully scraped {count} non-empty comments.\")\n",
    "                    else: print(\"Located comment elements, but failed to extract text.\"); await page.screenshot(path=\"playwright_debug_comments_found_but_empty.png\")\n",
    "                except PlaywrightTimeoutError:\n",
    "                    print(f\"Timed out waiting for the first comment element ('{comment_locator_css}') to become visible.\")\n",
    "                    await page.screenshot(path=\"playwright_debug_timeout_waiting_for_comments.png\")\n",
    "                except PlaywrightError as e: print(f\"Error scraping comments: {e}\"); await page.screenshot(path=\"playwright_debug_error_scraping_comments.png\")\n",
    "            else: print(\"Skipping comment scraping because '评论' tab was not successfully clicked.\")\n",
    "\n",
    "            print(\"\\n--- Taking final screenshot ---\")\n",
    "            await page.screenshot(path=\"playwright_final_state.png\")\n",
    "            print(\"Saved final screenshot: playwright_final_state.png\")\n",
    "\n",
    "            print(\"Closing browser context and browser (async)...\")\n",
    "            await context.close()\n",
    "            await browser.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- An critical error occurred during the Playwright Async process ---\")\n",
    "        print(f\"Error Type: {type(e).__name__}\")\n",
    "        print(f\"Error Details: {e}\") # This might now show more details\n",
    "        if browser and not browser.is_closed():\n",
    "            try:\n",
    "                print(\"Attempting to close browser after error (async)...\")\n",
    "                await browser.close()\n",
    "                print(\"Browser closed after error.\")\n",
    "            except Exception as close_err:\n",
    "                print(f\"Error closing browser after main error: {close_err}\")\n",
    "\n",
    "    print(\"--- Playwright Async Scraper Finished ---\")\n",
    "    return scraped_data\n",
    "\n",
    "# --- How to run in a Jupyter Notebook ---\n",
    "async def main(): # Keep this as an async function\n",
    "    target_url = \"https://xueqiu.com/5669998349/334081638\"\n",
    "    data = await scrape_xueqiu_playwright_async(target_url) # await the call\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"      Scraped Data Summary (Playwright Async w/ nest_asyncio)\")\n",
    "    print(\"=\"*30)\n",
    "    print(\"\\n--- Main Post ---\")\n",
    "    if data[\"main_post\"]: print(data[\"main_post\"][:500] + ('...' if len(data[\"main_post\"]) > 500 else ''))\n",
    "    else: print(\">>> Main post content not found or scraping failed. <<<\")\n",
    "    print(\"\\n--- Comments ---\")\n",
    "    if data[\"comments\"]:\n",
    "        print(f\"Found {len(data['comments'])} comments:\")\n",
    "        for i, comment in enumerate(data[\"comments\"]): print(f\"{i+1}. {comment[:150]}\" + ('...' if len(comment) > 150 else ''))\n",
    "    else: print(\">>> No comments found or scraping failed. <<<\")\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"Check console logs and playwright_debug_*.png files for details.\")\n",
    "\n",
    "# To run this in a Jupyter Notebook cell, you STILL execute it like this:\n",
    "# await main()\n",
    "#\n",
    "# OR, because nest_asyncio is applied, you can sometimes get away with asyncio.run\n",
    "# if the top-level await isn't behaving as expected, but await main() is preferred.\n",
    "# if __name__ == \"__main__\":\n",
    "# asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b250bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Playwright Async Scraper (with nest_asyncio) ---\n",
      "\n",
      "--- An critical error occurred during the Playwright Async process ---\n",
      "Error Type: NotImplementedError\n",
      "Error Details: \n",
      "--- Playwright Async Scraper Finished ---\n",
      "\n",
      "==============================\n",
      "      Scraped Data Summary (Playwright Async w/ nest_asyncio)\n",
      "==============================\n",
      "\n",
      "--- Main Post ---\n",
      ">>> Main post content not found or scraping failed. <<<\n",
      "\n",
      "--- Comments ---\n",
      ">>> No comments found or scraping failed. <<<\n",
      "\n",
      "==============================\n",
      "Check console logs and playwright_debug_*.png files for details.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
